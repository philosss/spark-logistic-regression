{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****Worker: 8****\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "Best parameters: (0.5, 0)\n",
      "Split train/test done. Train contains 1 elements, Test contains 0 elements\n",
      "b: 0.25\n",
      "[-0.0855991229370825, 0.08271223578137651, 0.17819532540544952, -0.011723621718133783, 0.0028908634400629397, -0.08755702754164972, -0.0729405436671034, -0.06563325596098812, -0.08081680569620409, -0.09283100663187886, -0.07420681613626252, 0.02851873344344984, -0.0780053231271851, -0.043727038988629945, -0.04752343598508661, 0.02154051784415609, -0.08027512843329017, 0.5202451136825065, 0.03772224357872716, -0.04196871664391589, 0.031278699800448596, -0.029539666573631475, -0.0725444158808804, -0.05324281014056021, -0.08219473356820056, -0.0748018533014259, -0.05696751118741593, -0.057951240305905184, -0.041678332476904466, -0.05630375989049854, -0.040130464963906196, -0.03579911421235941, -0.04372531181573418, -0.03629984154690151, -0.04951146604779623, -0.06052597705787563, -0.08085511517083391, -0.014957433514830249, -0.045222920748787185, -0.046320927696213876, -0.03022288617773664, -0.043145301024935676, -0.051492681707850436, -0.03183237026016123, -0.07443596175550131, -0.04934150721488869, -0.01784503656441755, -0.027883526981723916, -0.03960903529324233, -0.12856266379584097, -0.03879520211994327, 0.15598468992946002, -0.07708035747803593, -0.02575930145764528, -0.011310589707729834, 0.011323249221853503]\n",
      "cost:0.10053568010963648\n",
      "-> Iteration done: 1 of 50. Cost: 0.10053568010963648\n",
      "b: 0.297823577785764\n",
      "[-0.05917418672524021, 0.057178498057588706, 0.12318541472507294, -0.008104472999739066, 0.0019984374504069553, -0.060527675040138326, -0.05042338288875024, -0.04537189646762716, -0.05586819802253962, -0.06417354678230117, -0.05129874984303702, 0.019714838190462092, -0.05392463611669892, -0.030228253295970495, -0.03285268094246157, 0.014890837444740592, -0.055493739612211684, 0.3596424874886892, 0.02607717238952676, -0.029012735061913944, 0.021622787232001558, -0.02042060345541413, -0.05014954200364859, -0.03680645175943909, -0.056820751721616235, -0.05171009565023315, -0.03938131640383903, -0.04006136274715643, -0.028811994139212933, -0.038922468908266214, -0.02774196213307408, -0.024747723998964584, -0.03022705931117329, -0.025093873956767366, -0.0342269948151941, -0.04184126361648455, -0.055894681144414086, -0.010339988698102636, -0.03126234784690986, -0.03202139380326148, -0.02089290928099344, -0.029826101151092698, -0.035596597930137114, -0.022005536471048862, -0.05145715690604014, -0.03410950324087661, -0.012336172259121678, -0.01927572357706965, -0.02738150076808295, -0.0888746381074622, -0.026818902525161812, 0.10783132877364926, -0.05328521262543936, -0.017807258556689215, -0.007818946320626836, 0.007827697770722362]\n",
      "cost:0.17121135054250156\n",
      "-> Iteration done: 2 of 50. Cost: 0.17121135054250156\n",
      "b: 0.37650184703699957\n",
      "[-0.056526256731073664, 0.05461987125750964, 0.11767310652878243, -0.007741813564425383, 0.0019090112536267777, -0.057819179071108215, -0.04816703438026258, -0.04334159217114912, -0.05336820460563274, -0.06130190512973538, -0.04900323036250169, 0.018832637449502896, -0.05151161332247066, -0.028875597636412054, -0.03138258723994479, 0.014224501373384523, -0.053010502482313517, 0.3435491842681522, 0.024910269542954527, -0.027714471483912276, 0.02065520947491383, -0.019506821088794667, -0.04790544734322236, -0.03515943448744519, -0.05427813337565793, -0.049396169243280615, -0.03761907893702465, -0.038268694526502466, -0.027522713327848086, -0.03718076397621935, -0.026500563176966987, -0.023640311387305282, -0.028874457080116905, -0.023970971806400898, -0.03269540323452473, -0.03996894828685685, -0.05339350265920917, -0.009877294274600393, -0.029863418463456387, -0.03058849858662966, -0.019957992145462355, -0.028491441019408342, -0.03400371926858227, -0.021020831428460385, -0.049154549016916085, -0.03258316918009748, -0.011784152496014388, -0.01841317236270349, -0.02615623175837512, -0.0848976705648721, -0.02561880869477691, 0.10300608612018682, -0.05090080279127328, -0.017010418301578047, -0.0074690636499735044, 0.007477423489664514]\n",
      "cost:0.1685682932800815\n",
      "-> Iteration done: 3 of 50. Cost: 0.1685682932800815\n",
      "b: 0.454065065906081\n",
      "[-0.05482050239501818, 0.05297164461700271, 0.11412216536787148, -0.007508194131260399, 0.0018514043217022986, -0.056074409098510775, -0.046713530601656617, -0.04203370247434482, -0.051757748656875185, -0.05945203930576996, -0.0475244932674693, 0.018264337780524616, -0.04995718246390443, -0.028004238400493868, -0.030435576286860604, 0.013795258287090792, -0.05141084066681638, 0.33318213460658164, 0.024158569311195727, -0.02687815076078217, 0.020031911291706866, -0.018918177039478398, -0.04645983729840474, -0.03409845218827147, -0.05264021912637366, -0.047905574699365974, -0.03648387362313787, -0.03711388620557786, -0.026692179159941983, -0.03605878539426545, -0.02570087373773733, -0.022926933817542544, -0.028003132261988938, -0.023247616122461637, -0.03170877632763961, -0.038762832566648454, -0.05178228330832528, -0.009579233895022245, -0.028962250431477404, -0.029665450305796155, -0.019355733414567665, -0.027631674215982123, -0.03297761220013892, -0.020386500120672287, -0.047671245681948124, -0.031599929083803824, -0.01142855015509791, -0.0178575306058533, -0.02536693297375926, -0.08233577140399181, -0.024845727359786098, 0.09989774164099144, -0.04936480394594039, -0.01649710649828498, -0.007243674805142867, 0.007251782375647373]\n",
      "cost:0.16280072939962306\n",
      "-> Iteration done: 4 of 50. Cost: 0.16280072939962306\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function JavaObject.__init__.<locals>.<lambda> at 0x115187730>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/Cellar/apache-spark/2.3.2/libexec/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1293, in <lambda>\n",
      "  File \"/usr/local/Cellar/apache-spark/2.3.2/libexec/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 625, in _garbage_collect_object\n",
      "  File \"/usr/local/Cellar/apache-spark/2.3.2/libexec/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 919, in garbage_collect_object\n",
      "KeyboardInterrupt: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b: 0.5291848139910746\n",
      "[-0.053130989402829266, 0.051339111570275785, 0.11060503450145914, -0.007276799106070084, 0.0017943458943137348, -0.05434625195725372, -0.045273866362649476, -0.04073826585232177, -0.050162626668168536, -0.057619786983537466, -0.0460598359711166, 0.017701449178162458, -0.04841755212236293, -0.027141175813561257, -0.02949758230076243, 0.013370102239838666, -0.049826410035005285, 0.322913794832406, 0.023414026394936886, -0.026049793067356865, 0.0194145478435968, -0.01833513776584282, -0.045027991632981386, -0.03304757203451986, -0.05101790028141244, -0.046429172854858064, -0.03535947716927992, -0.03597007339475906, -0.025869552925041693, -0.034947489733981624, -0.024908798543357865, -0.0222203486739647, -0.027140103765137473, -0.02253114787134454, -0.030731543591136494, -0.03756820088006713, -0.050186405186227426, -0.009284011498039485, -0.028069662873004816, -0.028751190831309257, -0.01875920909157589, -0.02678009368416862, -0.03196127521252742, -0.019758208599902374, -0.046202065623124004, -0.030626050910367266, -0.011076333682695148, -0.017307179393279554, -0.024585149499351585, -0.07979826537191317, -0.02408000692051926, 0.0968189932709633, -0.04784343011717548, -0.015988682194517392, -0.007020432000720985, 0.007028289704020632]\n",
      "cost:0.15751599961134755\n",
      "-> Iteration done: 5 of 50. Cost: 0.15751599961134755\n",
      "b: 0.6020532411806646\n",
      "[-0.05151538853034886, 0.049777997908031626, 0.10724176963005874, -0.00705552705529955, 0.001739783635545963, -0.052693697524049364, -0.043897183962826464, -0.039499501458996826, -0.048637287420360616, -0.05586769128253437, -0.04465925389994444, 0.017163185594934627, -0.046945276895956366, -0.026315870133818, -0.02860062328989491, 0.01296354574453114, -0.0483112944230074, 0.31309467016465775, 0.022702055436046274, -0.025257674025709304, 0.018824192557774524, -0.017777605054623127, -0.043658785762999766, -0.03204266535364623, -0.0494665539742349, -0.0450173600311944, -0.034284270349169435, -0.03487629963648867, -0.025082914604428193, -0.03388481057931461, -0.02415137472890609, -0.021544674926722858, -0.02631483068411651, -0.02184602337868845, -0.029797062430583027, -0.03642583144931598, -0.048660342884041, -0.009001704369093904, -0.027216123868036794, -0.027876928004397915, -0.018188781269394615, -0.025965767747318177, -0.03098940051756463, -0.019157403318249697, -0.0447971586494334, -0.02969477755883461, -0.010739525831706898, -0.016780904719266642, -0.023837567166937905, -0.07737176911038447, -0.023347784904189678, 0.09387493271874414, -0.04638861272513105, -0.01550250022814319, -0.006806955530716641, 0.006814574297899169]\n",
      "cost:0.15246461607292985\n",
      "-> Iteration done: 6 of 50. Cost: 0.15246461607292985\n",
      "b: 0.6727586043410858\n",
      "[-0.04996696255909426, 0.04828179362894626, 0.10401834560015633, -0.006843455252193976, 0.0016874900152803202, -0.05110985448034206, -0.04257774249781766, -0.03831224352198859, -0.04717537009504154, -0.05418844578708504, -0.0433169064855444, 0.016647302417444797, -0.04553421724859268, -0.025524879753392907, -0.027740958844773768, 0.012573893419603927, -0.04685917564600464, 0.30368381386375376, 0.02201968744386222, -0.024498490419594197, 0.01825838359319331, -0.01724325393821704, -0.042346509961972985, -0.031079541583501777, -0.047979710934372186, -0.04366424882659668, -0.03325376944199112, -0.03382800378394779, -0.024328983837015324, -0.03286631645107673, -0.023425443760731232, -0.0208970949481865, -0.02552387154699482, -0.021189385606301892, -0.0289014359653487, -0.035330960478723666, -0.047197732568146473, -0.008731135259002664, -0.026398074072890174, -0.027039016060952617, -0.01764207120650908, -0.025185300584194166, -0.030057935299812488, -0.018581578857131614, -0.04345066615718847, -0.028802225525462292, -0.010416722079446, -0.01627651196537809, -0.02312106848283951, -0.07504616388541652, -0.022646007871184964, 0.09105328295508473, -0.044994285034644, -0.015036533171357901, -0.006602355176732562, 0.00660974494249802]\n",
      "cost:0.14764536986351426\n",
      "-> Iteration done: 7 of 50. Cost: 0.14764536986351426\n",
      "b: 0.7413900977194763\n",
      "[-0.04848266383575675, 0.046847553863838765, 0.1009284179825751, -0.0066401662913724, 0.0016373621078182026, -0.04959160546399615, -0.04131294500772885, -0.037174155248549334, -0.045773997307527556, -0.05257874536140296, -0.042030151683921546, 0.016152784270659235, -0.04418159589502678, -0.024766647823915557, -0.026916896950902214, 0.012200378340955161, -0.045467195605077504, 0.29466270323124055, 0.021365579363496884, -0.023770748003582927, 0.017716007309553253, -0.016731032692500716, -0.04108858137365787, -0.030156305078185914, -0.046554444717684176, -0.04236717601149091, -0.03226594618836563, -0.03282312255327087, -0.023606276716151755, -0.031890002721951305, -0.022729576842133843, -0.020276334154164397, -0.024765669566895875, -0.020559942142202116, -0.028042901399529266, -0.034281433014034635, -0.045795695489897564, -0.008471771626424481, -0.025613903380132537, -0.026235805800330726, -0.017118002853587257, -0.024437156058503218, -0.029165046224577856, -0.018029601863480717, -0.042159937943941475, -0.02794663806552489, -0.010107287074954832, -0.015793008372338466, -0.022434243215230125, -0.07281687237875822, -0.0219732945652253, 0.08834849033363844, -0.04365770269275315, -0.01458986389536833, -0.006406228238893284, 0.0064133984872150225]\n",
      "cost:0.1430448462725692\n",
      "-> Iteration done: 8 of 50. Cost: 0.1430448462725692\n",
      "b: 0.808032498180549\n",
      "[-0.04705945603743697, 0.045472344691812036, 0.09796566593513209, -0.0064452443192622045, 0.0015892973701128962, -0.04813584470244525, -0.04010020418751029, -0.0360829085335397, -0.04443030237052832, -0.051035297157366155, -0.040796357273536775, 0.015678619554453505, -0.042884645875262375, -0.02403962328498665, -0.026126751884268294, 0.011842236435714113, -0.04413250682700023, 0.2860128844314039, 0.020738393133203102, -0.02307295808747599, 0.01719595420678931, -0.01623989350339641, -0.03988242674422188, -0.029271067239333266, -0.045187839759814885, -0.041123488257521615, -0.03131877986947247, -0.031859600331363404, -0.02291331485197828, -0.030953872217322403, -0.022062350488321662, -0.01968112269904914, -0.024038673744685664, -0.019956405379269442, -0.0272197024908528, -0.03327510211257191, -0.04445136360311226, -0.008223082909872993, -0.024862007668306388, -0.02546565415320328, -0.016615504161778205, -0.02371980374492079, -0.02830890677304542, -0.017500343197751584, -0.04092233366003159, -0.02712626496543253, -0.009810587829351014, -0.01532940487170192, -0.021775686375171136, -0.07067933428947787, -0.02132826886519472, 0.08575502185512054, -0.042376131549312225, -0.014161578681035729, -0.0062181735144603185, 0.0062251332802606765]\n",
      "cost:0.13865097971383375\n",
      "-> Iteration done: 9 of 50. Cost: 0.13865097971383375\n",
      "b: 0.8727665938288369\n",
      "[-0.045694455265193085, 0.04415337947532748, 0.09512408592306265, -0.00625829435821517, 0.0015431984067971393, -0.04673962233346633, -0.0389370626152927, -0.035036292143118514, -0.04314156250497284, -0.04955497362842264, -0.039613023170847306, 0.015223847451211983, -0.04164073913119439, -0.02334233293971886, -0.025368922544509676, 0.011498741987606063, -0.042852404782216906, 0.277716830014413, 0.020136857862174895, -0.022403706713590564, 0.016697170481939944, -0.015768841157282172, -0.038725601997639275, -0.028422034276557255, -0.04387712685826517, -0.03993066543389561, -0.0304103512069406, -0.030935484697279227, -0.022248694070073443, -0.030056028021100266, -0.021422412673695906, -0.01911025448371199, -0.02334141094166662, -0.019377552348493983, -0.026430171160726393, -0.03230992860856835, -0.0431620128380445, -0.007984565182144208, -0.024140863343140917, -0.02472700053261818, -0.016133556899276785, -0.023031790045749827, -0.027487782117974043, -0.016992730403407756, -0.039735345501827474, -0.026339443872633424, -0.009526023129908306, -0.014884762046437086, -0.021144063504422203, -0.06862921824457352, -0.02070962373150563, 0.08326762227780903, -0.041146974709005704, -0.013750809678087027, -0.006037809941145052, 0.006044567832837801]\n",
      "cost:0.134452459432827\n",
      "-> Iteration done: 10 of 50. Cost: 0.134452459432827\n",
      "b: 0.9356693750347947\n",
      "[-0.04438491923872929, 0.04288800841930983, 0.09239796922514512, -0.006078940826616324, 0.0014989726052648963, -0.04540013335271883, -0.03782118354498802, -0.03403220342975391, -0.04190518863837735, -0.04813480081138691, -0.0384777720630639, 0.014787554325863421, -0.04044737665987466, -0.022673375935004136, -0.024641886455955823, 0.011169204917858954, -0.041624317751586114, 0.2697578732449639, 0.019559765068809534, -0.021761649358983608, 0.016218654080787792, -0.015316929312153432, -0.037615783078295766, -0.027607500486526673, -0.042619672796822654, -0.038786311165026795, -0.029538835171750214, -0.030048919106944565, -0.021611079150332273, -0.029194666368409387, -0.020808477766119743, -0.01856258263652455, -0.022672480360062947, -0.018822220136789726, -0.025672721244326138, -0.03138397347287767, -0.0419250528949162, -0.007755739262216215, -0.023449021628991783, -0.024018360986836823, -0.015671192836241334, -0.02237173274462178, -0.026700022623694794, -0.01650574368867172, -0.03859658881555911, -0.025584594067158045, -0.009253021287449651, -0.014458186611145746, -0.020538105675530636, -0.06666240557030637, -0.020116116308919626, 0.08088129442735251, -0.039967762801374485, -0.0133567316534778, -0.005864775169355279, 0.005871339389790033]\n",
      "cost:0.13043868802068823\n",
      "-> Iteration done: 11 of 50. Cost: 0.13043868802068823\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b: 0.9968142223072268\n",
      "[-0.043128240813932836, 0.04167371230730955, 0.08978188843888274, -0.005906826651048394, 0.0014565319167448723, -0.04411471098300862, -0.03675034538246681, -0.0330686433617852, -0.040718719284549544, -0.046771951296302905, -0.03738834378843284, 0.014368871566143478, -0.03930218260613112, -0.02203142045004391, -0.02394419616865521, 0.010852969153929566, -0.040445800747106644, 0.2621201687038657, 0.019005965823983784, -0.021145507757140664, 0.015759452329108622, -0.01488325826056977, -0.036550760457164794, -0.026825844220861945, -0.041412974120914804, -0.03768814716575562, -0.02870249667005556, -0.029198138504482614, -0.020999200670646014, -0.028368072381677573, -0.020219323487818797, -0.01803701680227455, -0.022030550231681618, -0.018289303137989973, -0.024945844741069895, -0.030495393229312967, -0.04073802112072028, -0.007536149582515517, -0.02278510514408746, -0.023338324691427877, -0.015227491455999888, -0.021738317739082087, -0.025944059946545285, -0.01603841351584413, -0.037503796460246444, -0.024860212724962923, -0.008991038784933934, -0.014048829300429864, -0.019956606492220016, -0.0647749805560881, -0.01954656498856807, 0.07859128738397428, -0.03883614814348314, -0.012978560040627932, -0.005698724705638771, 0.005705103072086689]\n",
      "cost:0.1265997301844783\n",
      "-> Iteration done: 12 of 50. Cost: 0.1265997301844783\n",
      "b: 1.056271085174724\n",
      "[-0.04192194166315899, 0.040508096394924344, 0.08727068432448473, -0.005741612400746162, 0.001415792642870369, -0.04288082021002246, -0.03572243630041602, -0.03214371167777184, -0.039579814576948244, -0.045463737372804805, -0.03634258985760576, 0.013966973477079345, -0.03820289850349695, -0.02141520046801664, -0.023274475749757897, 0.010549411039184237, -0.03931452958526874, 0.2547886538787578, 0.01847436796605071, -0.02055406679945894, 0.015318659623389838, -0.014466972748764868, -0.03552843377591114, -0.026075523955260867, -0.04025465106923726, -0.03663400771878788, -0.02789968633731897, -0.028381465043719613, -0.02041185192982405, -0.027574615913774213, -0.019653787952580874, -0.017532520499145755, -0.021414354589707446, -0.017777750372858978, -0.02424810815922519, -0.02964243548606204, -0.039598576539751976, -0.007325363084621629, -0.02214780456175705, -0.02268555052943009, -0.014801577723718592, -0.02113029585520698, -0.025218403233206007, -0.015589818251145266, -0.03645481331215163, -0.02416487127508649, -0.008739558959971153, -0.013655882810272992, -0.01939841916508666, -0.06296322096280187, -0.01899984654373324, 0.076393084966247, -0.03774989904913853, -0.012615549037632904, -0.005539331077631455, 0.005545531040836294]\n",
      "cost:0.12292626589668547\n",
      "-> Iteration done: 13 of 50. Cost: 0.12292626589668547\n",
      "b: 1.1141066524982846\n",
      "[-0.04076366618144103, 0.039388884521526286, 0.0848594531191651, -0.005582975452993421, 0.0013766752298791064, -0.041696051549155, -0.03473544904571152, -0.0312556022140708, -0.03848625051534586, -0.04420760442149017, -0.035338468170866486, 0.013581075250744975, -0.03714737772102216, -0.020823512663155803, -0.022631417400328566, 0.01025793779943232, -0.03822829517227851, 0.24774901212793132, 0.017963933415398276, -0.01998617154750003, 0.014895415204104078, -0.01406725987372163, -0.03454680668246375, -0.025355074499150157, -0.03914244172232183, -0.03562183434956086, -0.027128836482801455, -0.027597303962643906, -0.019847885980519044, -0.02681274753975321, -0.0191107668088736, -0.017048108570183886, -0.020822690155904038, -0.017286562904911124, -0.023578148991194633, -0.028823434626851246, -0.03850449409754407, -0.007122968154449407, -0.021535875391016653, -0.022058763793771707, -0.014392619934838495, -0.02054647977609533, -0.02452163545494327, -0.0151590818985729, -0.03544759096569296, -0.02349721188703385, -0.008498090734436671, -0.013278579813015758, -0.018862453691837765, -0.06122358887044358, -0.018474893368023118, 0.07428239462656361, -0.036706894341549556, -0.012266989773462609, -0.005386283028858054, 0.005392311691186006]\n",
      "cost:0.11940954732390763\n",
      "-> Iteration done: 14 of 50. Cost: 0.11940954732390763\n",
      "b: 1.1703845145490834\n",
      "[-0.03965117562001051, 0.03831391344163296, 0.08254353432464293, -0.0054306091896522395, 0.0013391040704897926, -0.04055811504484533, -0.03378747594048581, -0.030402598406704437, -0.037435913427101675, -0.04300112455180776, -0.034374037932415544, 0.013210431011748378, -0.03613358011722992, -0.02025521340394597, -0.022013778198358973, 0.009977986066660907, -0.03718499800245471, 0.24098763702567066, 0.017473675589180095, -0.019440724356691468, 0.014488901012044017, -0.013683347058690516, -0.03360398185923174, -0.02466310334672436, -0.03807419636937433, -0.03464967069974738, -0.026388457185331657, -0.02684413961175565, -0.019306212772829755, -0.02608099469811171, -0.018589210489529315, -0.01658284472982776, -0.020254413343928225, -0.016814791352625078, -0.02293467232028006, -0.02803680766283738, -0.03745365911951461, -0.00692857359715115, -0.020948134877246137, -0.021456753012696058, -0.013999827643769877, -0.019985741084933742, -0.02385240987859203, -0.014745371918291669, -0.03448018263202504, -0.022855944089188927, -0.008266167391473343, -0.01291619104637662, -0.018347674142712135, -0.05955272186716405, -0.017970690816567658, 0.07225513676082893, -0.03570511807067544, -0.011932208542564514, -0.0052392847435682455, 0.00524514887629015]\n",
      "cost:0.11604135918212337\n",
      "-> Iteration done: 15 of 50. Cost: 0.11604135918212337\n",
      "b: 1.225165317183013\n",
      "[-0.038582342447020426, 0.037281127375819026, 0.08031849896762062, -0.0052842222248098685, 0.0013030073134518189, -0.039464834502313265, -0.032876704076799365, -0.02958306896743651, -0.036426794642944405, -0.04184199048634374, -0.033447454761619366, 0.012854331938415281, -0.035159566901119876, -0.019709215872382113, -0.021420376967920353, 0.009709020459943866, -0.036182642869697024, 0.23449159808846592, 0.01700265691617113, -0.018916682111424422, 0.014098339627679238, -0.01331450010711403, -0.032698156243872734, -0.023998287169305438, -0.037047872093279255, -0.03371565759930396, -0.02567713254028186, -0.026120531636234692, -0.018785796408529284, -0.0253779579814941, -0.018088121567946945, -0.01613583920546094, -0.01970843737870317, -0.016361533498007456, -0.022316447558863355, -0.02728105024515163, -0.0364440619842257, -0.006741807651719734, -0.020383459022899668, -0.02087836689813529, -0.013622449672806177, -0.0194470074225808, -0.02320944667421406, -0.014347897129514085, -0.03355073823519192, -0.022239841518192187, -0.00804334539985913, -0.012568023476482983, -0.017853096051033905, -0.05794742457955086, -0.017486274650187907, 0.07030743443217628, -0.03474265443516582, -0.0116105651078389, -0.0050980551015941365, 0.0051037611613336895]\n",
      "cost:0.11281398220387653\n",
      "-> Iteration done: 16 of 50. Cost: 0.11281398220387653\n",
      "b: 1.2785069084394873\n",
      "[-0.03755514493400041, 0.03628857277974677, 0.07818013833017799, -0.0051435376633418035, 0.0012683166807183996, -0.0384141419501908, -0.03200141070366226, -0.028795463732928593, -0.035456985385875495, -0.04072800968991082, -0.03255696599994912, 0.012512104459179023, -0.034223495698877976, -0.019184487298540713, -0.020850091273639026, 0.009450532223154996, -0.03521933379064668, 0.22824860787315404, 0.01654998645110007, -0.01841305357082642, 0.013722992292997593, -0.012960021334449762, -0.03182761644136679, -0.02335936844810803, -0.03606152757235868, -0.032818028335777634, -0.024993517056772, -0.0254251113109306, -0.018285652505202546, -0.024702307575873633, -0.01760655222012126, -0.015706246473368532, -0.0191837295310987, -0.015925931990882145, -0.021722305317153086, -0.02655473283705559, -0.03547379300986396, -0.006562317045035727, -0.019840779727472783, -0.020322511416236207, -0.013259772200738188, -0.01892925975892904, -0.022591529658546588, -0.01396590569732612, -0.032657499704573975, -0.021647738798435977, -0.007829203285433562, -0.012233418534433452, -0.017377783908218543, -0.05640466054194054, -0.01702072858187123, 0.0684356035060287, -0.033817682907568175, -0.01130145107154352, -0.004962326963034709, 0.004967881107416046]\n",
      "cost:0.10972015943627501\n",
      "-> Iteration done: 17 of 50. Cost: 0.10972015943627501\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-ee9d99ac49ca>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    332\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n--------------------------------------------------\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Best parameters: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbest_par\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 334\u001b[0;31m     \u001b[0msmallest_error\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDATASET\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mITERATIONS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbest_par\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbest_par\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    335\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Best performance: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msmallest_error\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"--------------------------------------------------\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-18-ee9d99ac49ca>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(filename, iterations, learning_rate, lambda_reg, cv)\u001b[0m\n\u001b[1;32m    275\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0maverage_train_error\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage_test_error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m                                                  \u001b[0;31m#Testing the parameters and weights on the actual test set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 277\u001b[0;31m         \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_errors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgradientDescent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlambda_reg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    278\u001b[0m         \u001b[0mwBest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mOUTPUT\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"w_bestModel.csv\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"w+\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m         \u001b[0mwBest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-18-ee9d99ac49ca>\u001b[0m in \u001b[0;36mgradientDescent\u001b[0;34m(iterations, train, w, number_samples, lambda_reg, learning_rate, b, logCosts)\u001b[0m\n\u001b[1;32m    172\u001b[0m     \u001b[0mcosts\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0miteration\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 174\u001b[0;31m         \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgradientDescentIteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnumber_samples\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlambda_reg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    175\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"b: \"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-18-ee9d99ac49ca>\u001b[0m in \u001b[0;36mgradientDescentIteration\u001b[0;34m(train, w, number_samples, lambda_reg, learning_rate, b)\u001b[0m\n\u001b[1;32m    195\u001b[0m     \u001b[0mw_temp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_columns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 197\u001b[0;31m         \u001b[0mX_j\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    198\u001b[0m         \u001b[0;31m#print(\"X_j\"+str(X_j)+\"---\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m         \u001b[0mdw\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mnumber_samples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mX_j\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlambda_reg\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mnumber_samples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/apache-spark/2.3.2/libexec/python/pyspark/rdd.py\u001b[0m in \u001b[0;36msum\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1042\u001b[0m         \u001b[0;36m6.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1043\u001b[0m         \"\"\"\n\u001b[0;32m-> 1044\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmapPartitions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moperator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1045\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1046\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/apache-spark/2.3.2/libexec/python/pyspark/rdd.py\u001b[0m in \u001b[0;36mfold\u001b[0;34m(self, zeroValue, op)\u001b[0m\n\u001b[1;32m    913\u001b[0m         \u001b[0;31m# zeroValue provided to each partition is unique from the one provided\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m         \u001b[0;31m# to the final reduce call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mvals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmapPartitions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzeroValue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/apache-spark/2.3.2/libexec/python/pyspark/rdd.py\u001b[0m in \u001b[0;36mcollect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    812\u001b[0m         \"\"\"\n\u001b[1;32m    813\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mSCCallSiteSync\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcss\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 814\u001b[0;31m             \u001b[0msock_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPythonRDD\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollectAndServe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jrdd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrdd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    815\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_load_from_socket\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msock_info\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jrdd_deserializer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    816\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/apache-spark/2.3.2/libexec/python/pyspark/rdd.py\u001b[0m in \u001b[0;36m_jrdd\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2470\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2471\u001b[0m         wrapped_func = _wrap_function(self.ctx, self.func, self._prev_jrdd_deserializer,\n\u001b[0;32m-> 2472\u001b[0;31m                                       self._jrdd_deserializer, profiler)\n\u001b[0m\u001b[1;32m   2473\u001b[0m         python_rdd = self.ctx._jvm.PythonRDD(self._prev_jrdd.rdd(), wrapped_func,\n\u001b[1;32m   2474\u001b[0m                                              self.preservesPartitioning)\n",
      "\u001b[0;32m/usr/local/Cellar/apache-spark/2.3.2/libexec/python/pyspark/rdd.py\u001b[0m in \u001b[0;36m_wrap_function\u001b[0;34m(sc, func, deserializer, serializer, profiler)\u001b[0m\n\u001b[1;32m   2404\u001b[0m     \u001b[0mcommand\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprofiler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeserializer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mserializer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2405\u001b[0m     \u001b[0mpickled_command\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbroadcast_vars\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mincludes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_prepare_for_python_RDD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2406\u001b[0;31m     return sc._jvm.PythonFunction(bytearray(pickled_command), env, includes, sc.pythonExec,\n\u001b[0m\u001b[1;32m   2407\u001b[0m                                   sc.pythonVer, broadcast_vars, sc._javaAccumulator)\n\u001b[1;32m   2408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/apache-spark/2.3.2/libexec/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1647\u001b[0m             \u001b[0mproto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mREFLECTION_COMMAND_NAME\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1648\u001b[0m             \u001b[0mproto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mREFL_GET_UNKNOWN_SUB_COMMAND_NAME\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"\\n\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_id\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1649\u001b[0;31m             \"\\n\" + proto.END_COMMAND_PART)\n\u001b[0m\u001b[1;32m   1650\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0manswer\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mproto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSUCCESS_PACKAGE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1651\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mJavaPackage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gateway_client\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjvm_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/apache-spark/2.3.2/libexec/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36msend_command\u001b[0;34m(self, command, retry, binary)\u001b[0m\n\u001b[1;32m    983\u001b[0m         \u001b[0mconnection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_connection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 985\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconnection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    986\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbinary\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    987\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_connection_guard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconnection\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/apache-spark/2.3.2/libexec/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36msend_command\u001b[0;34m(self, command)\u001b[0m\n\u001b[1;32m   1150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1152\u001b[0;31m             \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msmart_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1153\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Answer received: {0}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manswer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0manswer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRETURN_MESSAGE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    584\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import math\n",
    "import random\n",
    "import pyspark\n",
    "from itertools import chain\n",
    "import datetime\n",
    "import os\n",
    "import time\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "\n",
    "global k_fold\n",
    "global n_row\n",
    "global y_h_m_y\n",
    "global n_columns\n",
    "global w\n",
    "global OUTPUT\n",
    "global ITERATIONS\n",
    "global THRESHOLD\n",
    "global averages\n",
    "global col_sums\n",
    "global sigmas\n",
    "global b\n",
    "\n",
    "DEBUG = True\n",
    "TRAIN_TEST = 0.8\n",
    "k_fold=3\n",
    "ITERATIONS=50\n",
    "THRESHOLD = 0.5\n",
    "\n",
    "DATASET=\"dataset/spam.data\"\n",
    "n_columns=56 #total number of columns (58) - the one deleted (57) - label (56)\n",
    "\n",
    "OUTPUT=\"out/\"\n",
    "\n",
    "def initializeAccumulators():\n",
    "    global averages\n",
    "    global col_sums\n",
    "    global sigmas\n",
    "    i=0\n",
    "    averages=[]\n",
    "    col_sums=[]\n",
    "    sigmas=[]\n",
    "    while(i<n_columns):\n",
    "        averages.append(sc.accumulator(0))\n",
    "        col_sums.append(sc.accumulator(0))\n",
    "        sigmas.append(sc.accumulator(0)) \n",
    "        i+=1\n",
    "\n",
    "def addToAccumulators(row):\n",
    "    if(len(row)!=len(col_sums)):\n",
    "        raise Exception(\"Number of columns in the row doesn't mach the number of accumulators initiated. Len row: \"+str(len(row))+\" n_accomulators: \"+str(len(col_sums)))\n",
    "    i=0\n",
    "    while(i<n_columns):\n",
    "        col_sums[i].add(row[i])\n",
    "        i+=1\n",
    "    #print(\"Col sum len: \" + str(len(col_sums)))\n",
    "        \n",
    "def preprocessing(row):\n",
    "    split=row.split(\" \")       #splitting\n",
    "    label = int(split[57])\n",
    "    del split[57] #label\n",
    "    del split[56] #col 57th\n",
    "    split=[float(col) for col in split]\n",
    "    addToAccumulators(split)\n",
    "    #assign random key to the datapoint\n",
    "    key=random.getrandbits(64)\n",
    "    #assign train/test \n",
    "    if(random.random()<TRAIN_TEST):\n",
    "        train=1\n",
    "    else:\n",
    "        train=0    \n",
    "    return (key,train,split,label)\n",
    "def calcAvg(n_row):\n",
    "    global averages\n",
    "    i=0\n",
    "    while(i<n_columns):\n",
    "        averages[i]=col_sums[i].value/n_row\n",
    "        i+=1\n",
    "def calcResiduals(row):\n",
    "    global sigmas\n",
    "    i=0\n",
    "    while(i<n_columns):       \n",
    "        sigmas[i].add(math.pow(row[2][i]-averages[i],2))\n",
    "        i+=1\n",
    "    return row\n",
    "def calcSigmas(n_row):\n",
    "    global sigmas\n",
    "    i=0\n",
    "    while(i<n_columns):\n",
    "        sigmas[i]=math.sqrt(sigmas[i].value/float(n_row-1))\n",
    "        i+=1\n",
    "\n",
    "def normalize(row):\n",
    "    i=0\n",
    "    while(i<n_columns):\n",
    "        row[2][i]=(row[2][i]-averages[i])/sigmas[i]\n",
    "        i+=1\n",
    "    return row\n",
    "\n",
    "def initializeWeights(random_init=False):\n",
    "    if(random_init):\n",
    "        #return sc.parallelize([(i, random.random()) for i in range(0,n_columns)])\n",
    "        return [random.random() for i in range(0,n_columns)]\n",
    "    else:\n",
    "        #return sc.parallelize([(i, 0.0) for i in range(0,n_columns)])\n",
    "        return [0.0 for i in range(0,n_columns)]\n",
    "\n",
    "def initializeBias():\n",
    "    return sc.parallelize(0.0)\n",
    "\n",
    "def sigmoid(z):\n",
    "    return 1/(1+math.exp(-z))\n",
    "\n",
    "def predict(w,b,X):\n",
    "    sig=sigmoid(sum([X[i]*w[i] for i in range(len(w))])+b)\n",
    "    #print(\"Sig: \"+str(sig)+\"w: \"+str(w)+\"b: \"+str(b)+\"X: \"+str(X))\n",
    "    return sig\n",
    "\n",
    "def classify_prediction(pred_probability):\n",
    "    if (pred_probability >= THRESHOLD):\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "def predict_parallel(w,b,X):\n",
    "    #Change X representation\n",
    "    X = sc.parallelize(X).zipWithIndex().map(lambda x: (x[1],x[0]))\n",
    "    wX_plus_b=X.join(w).map(lambda x: (x[1][0]*x[1][1])+b).sum()\n",
    "    return sigmoid(wX_plus_b)\n",
    "\n",
    "def compute_cost(dataset,w,b,lambda_reg, print_stats=False):\n",
    "    cost=0\n",
    "    #print(\"predict(w,b,x[2]))=\"+str(predict(w,b,dataset.collect()[0][2])))\n",
    "    #print(\"math.log(predict(w,b,x[2]))=\"+str(math.log(predict(w,b,dataset.collect()[0][2]))))\n",
    "    cost = (-1/dataset.count())*dataset.map(lambda x: x[3]*math.log(predict(w,b,x[2]))+(1-x[3])*math.log(1-predict(w,b,x[2]))).sum()+lambda_reg/(2*dataset.count())*sum([i*i for i in w])\n",
    "    \n",
    "    '''\n",
    "    print(\"RowNumber: \"+str(dataset.count()))\n",
    "    print(\"\\nlambda_reg: \"+str(lambda_reg))\n",
    "    print(\"\\nb: \"+str(b))\n",
    "    print(\"\\nw: \"+str(w))\n",
    "    print(\"\\nDataset: \"+str(w))\n",
    "    '''\n",
    "    if (print_stats):\n",
    "        stats = {\"TP\":0, \"TN\":0, \"FP\":0, \"FN\":0}\n",
    "        statsMapping = dataset.map(lambda x: 2*(classify_prediction(predict(w, b, x[2])) - x[3]) + x[3])  #this function maps all 4 possible variations to an integer, from -1 to 3\n",
    "        stats[\"TP\"] = statsMapping.filter(lambda x: x == 1).count()\n",
    "        stats[\"TN\"] = statsMapping.filter(lambda x: x == 2).count()\n",
    "        stats[\"FP\"] = statsMapping.filter(lambda x: x == -1).count()\n",
    "        stats[\"FN\"] = statsMapping.filter(lambda x: x == 0).count()\n",
    "        precision = stats[\"TP\"]/(stats[\"TP\"] + stats[\"FP\"])\n",
    "        recall = stats[\"TP\"]/(stats[\"TP\"] + stats[\"FN\"])\n",
    "        accuracy = (stats[\"TP\"] + stats[\"TN\"])/(stats[\"TP\"] + stats[\"TN\"] + stats[\"FP\"] + stats[\"FN\"])\n",
    "        print(\"Precision: \" + str(precision))\n",
    "        print(\"Recall: \" + str(recall))\n",
    "        print(\"F1 score: \" + str(2*(precision*recall)/(precision + recall)))\n",
    "        print(\"Accuracy: \" + str(accuracy))\n",
    "    return cost\n",
    "\n",
    "def make_folds(x):\n",
    "    return (x[0],int(random.random()*10-1),x[1],x[2])\n",
    "\n",
    "\n",
    "def touch(path):\n",
    "    with open(path, 'w+'):\n",
    "        os.utime(path, None)\n",
    "\n",
    "def gradientDescent(iterations,train,w,number_samples,lambda_reg,learning_rate,b,logCosts=False):\n",
    "    if(logCosts):\n",
    "        gd_cost_log = open(OUTPUT+\"gradient_descent.csv\",\"w+\")\n",
    "        gd_cost_log.write(\"iteration,cost\\r\\n\")\n",
    "        gd_cost_log.close()\n",
    "    costs=[]\n",
    "    for iteration in range(iterations):\n",
    "        w,b = gradientDescentIteration(train,w,number_samples,lambda_reg,learning_rate,b)\n",
    "        #print(\"b: \"+str(b))\n",
    "        #print(str(w))\n",
    "        \n",
    "        cost=compute_cost(train,w,b,lambda_reg)\n",
    "        #print(\"cost:\"+str(cost))\n",
    "        costs.append(cost)\n",
    "        if(logCosts):\n",
    "            gd_cost_log = open(OUTPUT+\"gradient_descent.csv\",\"a+\")            \n",
    "            gd_cost_log.write(str(iteration+1)+\",\"+str(cost)+\"\\r\\n\")\n",
    "            gd_cost_log.close()\n",
    "        print(\"-> Iteration done: \"+str(iteration+1)+\" of \"+str(iterations)+\". Cost: \"+str(cost))\n",
    "    return w,b,costs\n",
    "    \n",
    "global flag\n",
    "flag=True\n",
    "    \n",
    "def gradientDescentIteration(train,w,number_samples,lambda_reg,learning_rate,b):\n",
    "    global flag\n",
    "    dw=[0 for i in range(0,n_columns)]\n",
    "    j = 0\n",
    "    w_temp = w.copy()\n",
    "    for j in range(n_columns):\n",
    "        X_j=train.map(lambda x: (predict(w,b,x[2])-x[3])*x[2][j]).sum()\n",
    "        #print(\"X_j\"+str(X_j)+\"---\")\n",
    "        dw[j]=(1/number_samples)*X_j+(lambda_reg/number_samples)+w[j]\n",
    "        #print(\"w[j] \"+str(w[j]))\n",
    "        w_temp[j]-=learning_rate*dw[j]\n",
    "        #print(str(w[j]))\n",
    "    b-=learning_rate*(1/number_samples)*train.map(lambda x: predict(w,b,x[2])-x[3]).sum()\n",
    "    w = w_temp\n",
    "    return w_temp,b\n",
    "\n",
    "\n",
    "def kFoldsCV(k_fold,iterations,train,lambda_reg,learning_rate):\n",
    "    fold_length=train.count()/k_fold\n",
    "    train_errors_fold=[]\n",
    "    test_errors_fold = []\n",
    "    for i_fold in range(k_fold):\n",
    "        w=initializeWeights()\n",
    "        b=0\n",
    "        starting_fold=fold_length*i_fold\n",
    "        end_fold=starting_fold+fold_length\n",
    "        test_fold=train.zipWithIndex().filter(lambda t: (t[1]>=starting_fold and t[1]<end_fold)).map(lambda t: t[0]) #the map get rid of the index again\n",
    "        train_fold=train.zipWithIndex().filter(lambda t: t[1]<starting_fold or t[1]>=end_fold).map(lambda t: t[0])\n",
    "        train_fold_size=train_fold.count()\n",
    "        \n",
    "        #Gradient descent\n",
    "        w, b, train_errors = gradientDescent(iterations,train_fold,w,train_fold_size,lambda_reg,learning_rate,b)\n",
    "        train_errors_fold.append(train_errors)\n",
    "        train_errors_flattened =list(chain.from_iterable(train_errors_fold))\n",
    "        test_error = compute_cost(test_fold, w, b, lambda_reg)\n",
    "        test_errors_fold.append(test_error)\n",
    "        if(DEBUG):\n",
    "            print(\"--> Fold #\"+str(i_fold+1)+\" of \"+str(k_fold)+\" is done. Train error: \" \\\n",
    "                  +str(sum(train_errors_flattened)/((i_fold + 1) * iterations)) \\\n",
    "                  + \" Test error: \" + str(sum(test_errors_fold)/(i_fold+ 1)))\n",
    "    return w,b,train_errors_fold, test_errors_fold\n",
    "\n",
    "\n",
    "def trainTestSplit(dataset):\n",
    "    dataset=dataset.map(normalize)\n",
    "    train=dataset.filter(lambda x: x[1]==1)\n",
    "    #train_size=train.count()\n",
    "    test=dataset.filter(lambda x: x[1]==0)\n",
    "    return train, test\n",
    "\n",
    "def testParameters(test, w, b):\n",
    "    test_error = test.map(lambda x: ())\n",
    "\n",
    "def train(filename, iterations, learning_rate, lambda_reg, cv=False):\n",
    "    global w\n",
    "    global b\n",
    "    w = []\n",
    "    initializeAccumulators()\n",
    "    w = initializeWeights()\n",
    "    dataset=sc.textFile(filename).map(preprocessing)\n",
    "    n_row=dataset.count()\n",
    "    calcAvg(n_row)\n",
    "    gg = dataset.map(calcResiduals).collect()\n",
    "    dataset=dataset.collect()\n",
    "    calcSigmas(n_row)\n",
    "    dataset=sc.parallelize(sc.parallelize(dataset).take(1))#.sortBy(lambda x: x[0])\n",
    "    #dataset=sc.parallelize(dataset).sortBy(lambda x: x[0])\n",
    "    n_row=dataset.count()\n",
    "    '''\n",
    "    print(\"AVg\"+str(averages))\n",
    "    print(\"Sigmas\"+str(sigmas))\n",
    "    print(\"First:\"+str(train.take(1)))\n",
    "    '''\n",
    "    train, test = trainTestSplit(dataset)\n",
    "    print(\"Split train/test done. Train contains \"+str(train.count())+\" elements, Test contains \"+str(test.count())+\" elements\")\n",
    "    \n",
    "    if (cv):\n",
    "        w, b, train_errors_fold, test_errors_fold = kFoldsCV(k_fold,iterations,train,lambda_reg,learning_rate)\n",
    "        train_errors_fold =list(chain.from_iterable(train_errors_fold))\n",
    "        average_train_error = sum(train_errors_fold)/(iterations*k_fold)\n",
    "        average_test_error = sum(test_errors_fold)/k_fold\n",
    "        print(\"---> \"+str(k_fold)+\"-fold validation done.  Train error: \" \\\n",
    "            +str(average_train_error) \\\n",
    "            + \" Test error: \" + str((average_test_error)))\n",
    "        return average_train_error, average_test_error\n",
    "    else:                                                  #Testing the parameters and weights on the actual test set\n",
    "        w,b, train_errors = gradientDescent(iterations, train, w, train.count(), lambda_reg, learning_rate, b,True)\n",
    "        wBest = open(OUTPUT+\"w_bestModel.csv\",\"w+\")\n",
    "        wBest.write(str(w))\n",
    "        wBest.close()\n",
    "        average_train_error = sum(train_errors)/iterations\n",
    "        average_test_error = compute_cost(test, w, b, lambda_reg, True)\n",
    "        print(\"---> Model done. Train error: \" \\\n",
    "              +str(average_train_error) \\\n",
    "              + \" Test error: \" + str((average_test_error)))\n",
    "        return average_train_error, average_test_error\n",
    "            \n",
    "\n",
    "        \n",
    "workers = range(8,9) #8 cores\n",
    "\n",
    "working_time = open(OUTPUT+\"working_times.csv\",\"w+\")\n",
    "working_time.write(\"workers,grid_time,best_model_time,total\\r\\n\")\n",
    "working_time.close()\n",
    "grid_log = open(OUTPUT+\"grid.csv\",\"w+\")\n",
    "grid_log.write(\"learning_rate,lambda_red,train_error,test_error\\r\\n\")\n",
    "grid_log.close()\n",
    "for worker in workers:\n",
    "    global b\n",
    "    #working_time = open(OUTPUT+\"working_times.csv\",\"a+\")\n",
    "    print(\"****Worker: \"+str(worker)+\"****\\n\")\n",
    "    sc = pyspark.SparkContext.getOrCreate()\n",
    "    #sc.stop()\n",
    "    #conf = (SparkConf().set(\"spark.cores.max\", str(worker)))\n",
    "    #sc = SparkContext(conf=conf)\n",
    "    b = 0\n",
    "    col_sums=[]\n",
    "    averages=[]\n",
    "    sigmas=[]\n",
    "    w=[]\n",
    "    if (False):\n",
    "        grid=[]\n",
    "        for i in range(1,5):\n",
    "                for j in range(1,14,3):\n",
    "                    grid+=[(i*0.09,j*0.028)]\n",
    "\n",
    "        #grid=[(0.01,)] #(learning_rate,lambda_reg)\n",
    "        #grid=list(chain.from_iterable(grid))\n",
    "        grid_results = []\n",
    "        #workers_executioTime_grid=time.time()\n",
    "        for par in grid:\n",
    "            print(\"|---- Starting training for parameters (learning_rate,lambda_reg) = \"+str(par)+\" ----|\")\n",
    "            result=(par, train(DATASET,ITERATIONS,par[0],par[1], True))\n",
    "            grid_results.append(result)\n",
    "            grid_log = open(OUTPUT+\"grid.csv\",\"a+\")\n",
    "            grid_log.write(str(result[0][0])+\",\"+str(result[0][1])+\",\"+str(result[1][0])+\",\"+str(result[1][1])+\"\\r\\n\")\n",
    "            grid_log.close()\n",
    "        #workers_executioTime_grid=time.time()-workers_executioTime_grid\n",
    "        #workers_executioTime_bestTraining= time.time()\n",
    "        best_par = sorted(grid_results, key=lambda x: x[1])[0]\n",
    "    best_par = (0.5, 0)\n",
    "    print(\"\\n--------------------------------------------------\")\n",
    "    print(\"Best parameters: \" + str(best_par))\n",
    "    smallest_error = train(DATASET,ITERATIONS,best_par[0],best_par[1])\n",
    "    print(\"Best performance: \" + str(smallest_error))\n",
    "    print(\"--------------------------------------------------\")\n",
    "    \n",
    "    #workers_executioTime_bestTraining=time.time()-workers_executioTime_bestTraining\n",
    "    #working_time.write(str(worker)+\",\"+str(workers_executioTime_grid)+\",\"+str(workers_executioTime_bestTraining)+\",\"+str(workers_executioTime_grid+workers_executioTime_bestTraining)+\"\\r\\n\")\n",
    "    #working_time.close()\n",
    "    print(\"++++Worker \"+str(worker)+\" has terminated with running time: \"+str(workers_executioTime_grid+workers_executioTime_bestTraining)+\"++++\\n\")\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.02, 0.002),\n",
       " (0.02, 0.01),\n",
       " (0.02, 0.018000000000000002),\n",
       " (0.02, 0.026000000000000002),\n",
       " (0.04, 0.002),\n",
       " (0.04, 0.01),\n",
       " (0.04, 0.018000000000000002),\n",
       " (0.04, 0.026000000000000002),\n",
       " (0.06, 0.002),\n",
       " (0.06, 0.01),\n",
       " (0.06, 0.018000000000000002),\n",
       " (0.06, 0.026000000000000002),\n",
       " (0.08, 0.002),\n",
       " (0.08, 0.01),\n",
       " (0.08, 0.018000000000000002),\n",
       " (0.08, 0.026000000000000002)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid = []\n",
    "for i in range(1,5):\n",
    "    for j in range(1,14,4):\n",
    "        grid+=[(i*0.02,j*0.002)]\n",
    "grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
